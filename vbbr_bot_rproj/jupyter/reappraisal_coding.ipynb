{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load construct definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of val_list: 32\n"
     ]
    }
   ],
   "source": [
    "# Load the value definitions\n",
    "with open('other_vals copy 4.json') as f:\n",
    "    val_list = json.load(f)\n",
    "val_list\n",
    "print(f'length of val_list: {len(val_list)}')\n",
    "with open('schwartz_values_10.json') as f:\n",
    "    schwartz_list = json.load(f)\n",
    "schwartz_list\n",
    "\n",
    "\n",
    "with open(\"primals_beliefs.json\") as f:\n",
    "    belief_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    }
   ],
   "source": [
    "# load the participant data\n",
    "df = pd.read_csv('../data/proc/vbbr_bot_jan2025_proc.csv')\n",
    "pids = df['pid'].unique()\n",
    "print(len(pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "columns: Index(['id', 'issue_id', 'participant_id', 'domain', 'reap_num', 'text',\n",
      "       'success', 'believable', 'valued', 'relevance', 'created_at',\n",
      "       'updated_at', 'deleted_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load the reappraisals\n",
    "df_reaps = pd.read_csv('../data/raw/sql_export/reappraisals.csv')\n",
    "df_reaps = df_reaps[df_reaps['participant_id'].isin(pids)]\n",
    "# count unique participants\n",
    "print(len(df_reaps['participant_id'].unique()))\n",
    "print(f\"columns: {df_reaps.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: Index(['id', 'participant_id', 'domain', 'neg', 'pos', 'summary', 'created_at',\n",
      "       'updated_at', 'deleted_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_issues = pd.read_csv('../data/raw/sql_export/issues.csv')\n",
    "print(f\"columns: {df_issues.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: Index(['domain', 'participant_id', 'summary', 'id', 'text'], dtype='object')\n",
      "shape: (2692, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>46</td>\n",
       "      <td>It's understandable to feel anxious about bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>47</td>\n",
       "      <td>Social interactions can be daunting, especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>48</td>\n",
       "      <td>Feeling awkward can lead to anxiety, but it ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>49</td>\n",
       "      <td>People treating you differently based on perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>50</td>\n",
       "      <td>Networking and maintaining friendships might b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain            participant_id  \\\n",
       "0  relationship  6632edd68127fba862de05bf   \n",
       "1  relationship  6632edd68127fba862de05bf   \n",
       "2  relationship  6632edd68127fba862de05bf   \n",
       "3  relationship  6632edd68127fba862de05bf   \n",
       "4  relationship  6632edd68127fba862de05bf   \n",
       "\n",
       "                                             summary  id  \\\n",
       "0  You experience social anxiety and feel easily ...  46   \n",
       "1  You experience social anxiety and feel easily ...  47   \n",
       "2  You experience social anxiety and feel easily ...  48   \n",
       "3  You experience social anxiety and feel easily ...  49   \n",
       "4  You experience social anxiety and feel easily ...  50   \n",
       "\n",
       "                                                text  \n",
       "0  It's understandable to feel anxious about bein...  \n",
       "1  Social interactions can be daunting, especiall...  \n",
       "2  Feeling awkward can lead to anxiety, but it ca...  \n",
       "3  People treating you differently based on perce...  \n",
       "4  Networking and maintaining friendships might b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# join on domain and id/issue_id\n",
    "df_issues_reaps = pd.merge(\n",
    "    df_issues.loc[:, ['domain', 'participant_id', 'summary']],\n",
    "    df_reaps.loc[:, ['participant_id', 'id', 'domain', 'text']],\n",
    "    left_on=['domain', 'participant_id'],\n",
    "    right_on=['domain', 'participant_id'])\n",
    "\n",
    "print(f\"columns: {df_issues_reaps.columns}\")    \n",
    "print(f\"shape: {df_issues_reaps.shape}\")\n",
    "display(df_issues_reaps.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109594"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2962*37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages = pd.read_csv('../data/raw/sql_export/messages.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other vals batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_other_vals = \"\"\"\n",
    "# <ignore>{salt}</ignore>\n",
    "\n",
    "# Your task is to determine whether a given cognitive reappraisal for an issue reflects the value of {value}. \n",
    "# A value is only incorporated if the active ingredient of the reappraisal, i.e., the crux of what helps someone feel better, revolves around the value of {value}.\n",
    "\n",
    "# Very briefly (1-3 sentences) walk through your thought process about whether the reappraisal centers on the value of {value} and then ultimately decide whether it does or not by responding with one of the following codes:\n",
    "\n",
    "# - `Code[1]` for yes\n",
    "# - `Code[0]` for no\n",
    "\n",
    "# Be sure to format your response as `Code[1]` or `Code[0]` at the end of your response formatted just like that after walking through your thought process.\n",
    "\n",
    "# Issue: {issue}\n",
    "# Reappraisal: {reappraisal}\n",
    "\n",
    "# Does this cognitive reappraisal center on the value of {value}? \n",
    "\n",
    "# {description}\n",
    "\n",
    "# Be conservative with your answers. Only respond with `Code[1]` if the active ingredient of the given cognitive reappraisal centers around the value of {value} as described above.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_vals_o3 = \"\"\"\n",
    "<ignore>{salt}</ignore>\n",
    "\n",
    "Your task is to determine whether a given cognitive reappraisal for an issue reflects the value of {value}.\n",
    "\n",
    "{description}\n",
    "\n",
    "What does someone who values {value} care about? The value of {value} is incorporated in the reappraisal if the active ingredient of the reappraisal, i.e., the crux of what helps someone feel better, is congruent with the desires of someone who values {value}.\n",
    "\n",
    "Indicate whether the value is or is not incorporated in the reappraisal by responding with one of the following codes:\n",
    "\n",
    "- `Code[1]` for yes\n",
    "- `Code[0]` for no\n",
    "\n",
    "Be sure to format your response as `Code[1]` or `Code[0]`.\n",
    "\n",
    "<issue> {issue} </issue>\n",
    "<reappraisal> {reappraisal} </reappraisal>\n",
    "\n",
    "Does this cognitive reappraisal address the concerns of someone who values {value}? \n",
    "\n",
    "Be conservative with your answers. Only respond with `Code[1]` if the active ingredient of the given cognitive reappraisal explicitly centers around the value of {value} as described above. Do not say anything except `Code[1]` or `Code[0]`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of val_list: 32\n",
      "shape of df_issues_reaps: (2692, 5)\n",
      "estimated entries = 86144\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "print(f'length of val_list: {len(val_list)}')\n",
    "print(f'shape of df_issues_reaps: {df_issues_reaps.shape}')\n",
    "print(f'estimated entries = {len(val_list)*df_issues_reaps.shape[0]}')\n",
    "\n",
    "with open(\"batch_other_vals_o3.jsonl\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for _, row in df_issues_reaps.iterrows():\n",
    "        for val in val_list:\n",
    "            value_name = val['name']\n",
    "            description = val['description']\n",
    "            \n",
    "            # Extract needed fields\n",
    "            pid = row['participant_id']\n",
    "            domain = row['domain']\n",
    "            reap_id = row['id']             # The \"id\" column from your reappraisal df\n",
    "            issue = row['summary']\n",
    "            reappraisal = row['text']\n",
    "\n",
    "            # Generate a random salt\n",
    "            salt = os.urandom(2).hex()\n",
    "\n",
    "            # Format the system prompt\n",
    "            system_prompt = prompt_vals_o3.format(\n",
    "                salt=salt,\n",
    "                value=value_name,\n",
    "                issue=issue,\n",
    "                reappraisal=reappraisal,\n",
    "                description=description\n",
    "            )\n",
    "\n",
    "            # Construct the JSON for each line\n",
    "            value_name_clean = value_name.replace(\" \", \"_\").lower()\n",
    "            value_name_clean = value_name_clean.replace(\"-\", \"_\")\n",
    "            data = {\n",
    "                \"custom_id\": f\"{pid}-{domain}-{reap_id}-{value_name_clean}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"o3-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": system_prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    \"reasoning_effort\": \"low\",\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Write each request as one line of JSON\n",
    "            f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, model: str=\"gpt-4o\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "tokens = 0\n",
    "for _, row in df_issues_reaps.iterrows():\n",
    "    for val in val_list:\n",
    "        value_name = val['name']\n",
    "        description = val['description']\n",
    "        \n",
    "        # Extract needed fields\n",
    "        pid = row['participant_id']\n",
    "        domain = row['domain']\n",
    "        reap_id = row['id']             # The \"id\" column from your reappraisal df\n",
    "        issue = row['summary']\n",
    "        reappraisal = row['text']\n",
    "\n",
    "        # Generate a random salt\n",
    "        salt = os.urandom(2).hex()\n",
    "\n",
    "        # Format the system prompt\n",
    "        system_prompt = prompt_vals_o3.format(\n",
    "            salt=salt,\n",
    "            value=value_name,\n",
    "            issue=issue,\n",
    "            reappraisal=reappraisal,\n",
    "            description=description\n",
    "        )\n",
    "        tokens += num_tokens_from_string(system_prompt)\n",
    "        \n",
    "print(f\"Total tokens: {tokens}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.30924005000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokens * .55)/1e6 + (86144 * 2.2 * 250)/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-TVQzLMbWnpKv7wc2we97uD', bytes=106853228, created_at=1738733265, filename='batch_other_vals_o3.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67a2f6d456f48190b250694d308a9d12', completion_window='24h', created_at=1738733268, endpoint='/v1/chat/completions', input_file_id='file-TVQzLMbWnpKv7wc2we97uD', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1738819668, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "FileObject(id='file-5ttqjL32yVMLKeRFvfVE5o', bytes=78580680, created_at=1738733324, filename='batch_other_vals_o3.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67a2f70f8fec81908e650e8ce8dfb665', completion_window='24h', created_at=1738733327, endpoint='/v1/chat/completions', input_file_id='file-5ttqjL32yVMLKeRFvfVE5o', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1738819727, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 2 - vbbr_bot_streamlit - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to read and split the JSONL file into chunks of 50k lines\n",
    "def read_and_split_jsonl(file_path, max_lines=50000):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Split the lines into chunks of max_lines\n",
    "    chunks = [lines[i:i + max_lines] for i in range(0, len(lines), max_lines)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Read and split the original file\n",
    "file_path = \"batch_other_vals_o3.jsonl\"\n",
    "chunks = read_and_split_jsonl(file_path)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} - vbbr_bot_streamlit - other_vals_o3\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_67ab9622736c819085007114cdc811cb', completion_window='24h', created_at=1739298338, endpoint='/v1/chat/completions', input_file_id='file-WKUysKYLdbtqex3YdtyyB7', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1739309927, error_file_id=None, errors=None, expired_at=None, expires_at=1739384738, failed_at=None, finalizing_at=1739309679, in_progress_at=1739298341, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id='file-P8nrnzZEAbaEnPTkFzRxGZ', request_counts=BatchRequestCounts(completed=2709, failed=0, total=2709)),\n",
       " Batch(id='batch_67ab938d9e888190b6c6340480e408d2', completion_window='24h', created_at=1739297677, endpoint='/v1/chat/completions', input_file_id='file-RwDGW1TXuzBVJqH6n5CnWw', object='batch', status='cancelled', cancelled_at=1739298447, cancelling_at=1739297787, completed_at=None, error_file_id='file-UWXbCCPtLydspKXAD6vvtD', errors=None, expired_at=None, expires_at=1739384077, failed_at=None, finalizing_at=None, in_progress_at=1739297678, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=2709)),\n",
       " Batch(id='batch_67a53a475ed48190b8d6a055a3ce7b70', completion_window='24h', created_at=1738881607, endpoint='/v1/chat/completions', input_file_id='file-4jp7cXm8rUrD27ogiFbTsM', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738890869, error_file_id=None, errors=None, expired_at=None, expires_at=1738968007, failed_at=None, finalizing_at=1738889026, in_progress_at=1738881614, metadata={'description': 'Chunk 1 - reappraisal_intervention_clarity - schwartz_values_o3'}, output_file_id='file-E9pEZLTZUmixxZp8gXq8eW', request_counts=BatchRequestCounts(completed=11420, failed=0, total=11420)),\n",
       " Batch(id='batch_67a530e71d588190b754d20b987f7405', completion_window='24h', created_at=1738879207, endpoint='/v1/chat/completions', input_file_id='file-C7PqFzJquDe8qr3g8SXWEZ', object='batch', status='cancelled', cancelled_at=1738882847, cancelling_at=1738880706, completed_at=None, error_file_id='file-FbKpBSRF2zJc1yysaFRPJX', errors=None, expired_at=None, expires_at=1738965607, failed_at=None, finalizing_at=None, in_progress_at=1738879216, metadata={'description': 'Chunk 1 - reappraisal_intervention_clarity - other_vals_o3'}, output_file_id='file-7bXz2J4FHWmPZeDn36Q9dH', request_counts=BatchRequestCounts(completed=2567, failed=0, total=36544)),\n",
       " Batch(id='batch_67a40344cc348190adf4baab309b2cb4', completion_window='24h', created_at=1738801988, endpoint='/v1/chat/completions', input_file_id='file-VLb71KHTi1JU3pjeq8uVX5', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738809198, error_file_id=None, errors=None, expired_at=None, expires_at=1738888388, failed_at=None, finalizing_at=1738807730, in_progress_at=1738801994, metadata={'description': 'Chunk 2 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-XtzeW1rw6yS4tAnJecQwtQ', request_counts=BatchRequestCounts(completed=19992, failed=0, total=19992)),\n",
       " Batch(id='batch_67a40340be9c819087b8c1716b5f9259', completion_window='24h', created_at=1738801984, endpoint='/v1/chat/completions', input_file_id='file-QXUTcXFYe9UJcpWpDyHUwA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738822443, error_file_id=None, errors=None, expired_at=None, expires_at=1738888384, failed_at=None, finalizing_at=1738816791, in_progress_at=1738801997, metadata={'description': 'Chunk 1 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-4BsptATkWcHWSdq8f7xK1T', request_counts=BatchRequestCounts(completed=50000, failed=0, total=50000))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# client.batches.cancel(\"batch_abc123\")\n",
    "openai_files = client.batches.list(limit=6).data\n",
    "openai_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feb 5\n",
    "other_vals_1a_file_id = \"file-2LsupYC8AwH7mJiMrF3E8E\"\n",
    "other_vals_1b_file_id = \"file-QadV6TJE3ZCB6AT9rKsD7N\"\n",
    "data = [\n",
    "    (client.files.content(other_vals_1a_file_id).text, \"1a\"),\n",
    "    (client.files.content(other_vals_1b_file_id).text, \"1b\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# other_vals_1a_file_id = \"file-W3vNc6KvXoGgHFyvpa9b5Y\"\n",
    "# other_vals_1b_file_id = \"file-MVmQWB9omXsmJkcLgwZWNn\"\n",
    "# other_vals_2a_file_id = \"file-YCnGSaBAQcdvcQC8whnSF4\"\n",
    "# other_vals_2b_file_id = \"file-6NMKm4YCP5qeFVuiUwfaHa\"\n",
    "# other_vals_3a_file_id = \"file-5gTkpTa48ZKFAtid7aDqGx\"\n",
    "# other_vals_3b_file_id = \"file-AVwgg4wtnBicBDSKw4wuhW\"\n",
    "\n",
    "# data = [\n",
    "#     (client.files.content(other_vals_1a_file_id).text, \"1a\"),\n",
    "#     (client.files.content(other_vals_1b_file_id).text, \"1b\"),\n",
    "#     (client.files.content(other_vals_2a_file_id).text, \"2a\"),\n",
    "#     (client.files.content(other_vals_2b_file_id).text, \"2b\"),\n",
    "#     (client.files.content(other_vals_3a_file_id).text, \"3a\"),\n",
    "#     (client.files.content(other_vals_3b_file_id).text, \"3b\"),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_batch_output_to_pd(raw_data, batch_num):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'batch_num': batch_num,\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    df['code'] = df['code'].str.extract(r'(\\d)')\n",
    "    df['code'] = df['code'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_other_vals_coding = pd.concat([convert_batch_output_to_pd(data[i][0], data[i][1]) for i in range(len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_vals_coding.to_csv(\"df_other_vals_coding.tst.csv\", index=False)\n",
    "# df_other_vals_coding.to_csv(\"df_other_vals_coding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## redoing failed lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_vals_coding = pd.read_csv(\"df_other_vals_coding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2709, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_ids = df_other_vals_coding.loc[df_other_vals_coding['finish_reason'] != \"stop\", 'custom_id']\n",
    "df_other_vals_coding.loc[df_other_vals_coding['finish_reason'] != \"stop\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make failed lines file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"batch_other_vals_o3.jsonl\"\n",
    "new_file_path = \"batch_other_vals_o3_failed.jsonl\"\n",
    "# filter lines where the custom_id is in the failed_ids and write to new json\n",
    "with open(file_path, \"r\") as f_in, open(new_file_path, \"w\") as f_out:\n",
    "    for line in f_in:\n",
    "        data = json.loads(line)\n",
    "        if data['custom_id'] in failed_ids.values:\n",
    "            # remove data['body']['max_completion_tokens']\n",
    "            del data['body']['max_completion_tokens']\n",
    "            f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submit failed lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-WKUysKYLdbtqex3YdtyyB7', bytes=5738139, created_at=1739298337, filename='batch_other_vals_o3_failed.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67ab9622736c819085007114cdc811cb', completion_window='24h', created_at=1739298338, endpoint='/v1/chat/completions', input_file_id='file-WKUysKYLdbtqex3YdtyyB7', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1739384738, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read and split the original file\n",
    "file_path = new_file_path\n",
    "chunks = read_and_split_jsonl(file_path)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} - vbbr_bot_streamlit failed lines - other_vals_o3\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve redone lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_67ab9622736c819085007114cdc811cb', completion_window='24h', created_at=1739298338, endpoint='/v1/chat/completions', input_file_id='file-WKUysKYLdbtqex3YdtyyB7', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1739309927, error_file_id=None, errors=None, expired_at=None, expires_at=1739384738, failed_at=None, finalizing_at=1739309679, in_progress_at=1739298341, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id='file-P8nrnzZEAbaEnPTkFzRxGZ', request_counts=BatchRequestCounts(completed=2709, failed=0, total=2709)),\n",
       " Batch(id='batch_67ab938d9e888190b6c6340480e408d2', completion_window='24h', created_at=1739297677, endpoint='/v1/chat/completions', input_file_id='file-RwDGW1TXuzBVJqH6n5CnWw', object='batch', status='cancelled', cancelled_at=1739298447, cancelling_at=1739297787, completed_at=None, error_file_id='file-UWXbCCPtLydspKXAD6vvtD', errors=None, expired_at=None, expires_at=1739384077, failed_at=None, finalizing_at=None, in_progress_at=1739297678, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=2709)),\n",
       " Batch(id='batch_67a53a475ed48190b8d6a055a3ce7b70', completion_window='24h', created_at=1738881607, endpoint='/v1/chat/completions', input_file_id='file-4jp7cXm8rUrD27ogiFbTsM', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738890869, error_file_id=None, errors=None, expired_at=None, expires_at=1738968007, failed_at=None, finalizing_at=1738889026, in_progress_at=1738881614, metadata={'description': 'Chunk 1 - reappraisal_intervention_clarity - schwartz_values_o3'}, output_file_id='file-E9pEZLTZUmixxZp8gXq8eW', request_counts=BatchRequestCounts(completed=11420, failed=0, total=11420)),\n",
       " Batch(id='batch_67a530e71d588190b754d20b987f7405', completion_window='24h', created_at=1738879207, endpoint='/v1/chat/completions', input_file_id='file-C7PqFzJquDe8qr3g8SXWEZ', object='batch', status='cancelled', cancelled_at=1738882847, cancelling_at=1738880706, completed_at=None, error_file_id='file-FbKpBSRF2zJc1yysaFRPJX', errors=None, expired_at=None, expires_at=1738965607, failed_at=None, finalizing_at=None, in_progress_at=1738879216, metadata={'description': 'Chunk 1 - reappraisal_intervention_clarity - other_vals_o3'}, output_file_id='file-7bXz2J4FHWmPZeDn36Q9dH', request_counts=BatchRequestCounts(completed=2567, failed=0, total=36544)),\n",
       " Batch(id='batch_67a40344cc348190adf4baab309b2cb4', completion_window='24h', created_at=1738801988, endpoint='/v1/chat/completions', input_file_id='file-VLb71KHTi1JU3pjeq8uVX5', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738809198, error_file_id=None, errors=None, expired_at=None, expires_at=1738888388, failed_at=None, finalizing_at=1738807730, in_progress_at=1738801994, metadata={'description': 'Chunk 2 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-XtzeW1rw6yS4tAnJecQwtQ', request_counts=BatchRequestCounts(completed=19992, failed=0, total=19992)),\n",
       " Batch(id='batch_67a40340be9c819087b8c1716b5f9259', completion_window='24h', created_at=1738801984, endpoint='/v1/chat/completions', input_file_id='file-QXUTcXFYe9UJcpWpDyHUwA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738822443, error_file_id=None, errors=None, expired_at=None, expires_at=1738888384, failed_at=None, finalizing_at=1738816791, in_progress_at=1738801997, metadata={'description': 'Chunk 1 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-4BsptATkWcHWSdq8f7xK1T', request_counts=BatchRequestCounts(completed=50000, failed=0, total=50000))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# client.batches.cancel(\"batch_abc123\")\n",
    "openai_files = client.batches.list(limit=6).data\n",
    "openai_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"file-P8nrnzZEAbaEnPTkFzRxGZ\"\n",
    "data = [\n",
    "    (client.files.content(file_id).text, \"2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_batch_output_to_pd(raw_data, batch_num):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'batch_num': batch_num,\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    df['code'] = df['code'].str.extract(r'(\\d)')\n",
    "    df['code'] = df['code'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_other_vals_coding_failed = pd.concat([convert_batch_output_to_pd(data[i][0], data[i][1]) for i in range(len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_vals_coding_failed.to_csv(\"df_other_vals_coding_failed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## redo failed 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_redo = pd.read_csv(\"~/Downloads/tmpasldkfj.csv\")\n",
    "val_map = {\n",
    "    \"personalGrowth\": \"growth\",\n",
    "    \"interpersonalConnection\": \"connection\",\n",
    "    \"humanDiversity\": \"diversity\",\n",
    "    \"interpersonalHarmony\": \"interpersonal_harmony\",\n",
    "    \"selfControl\": \"self_control\",\n",
    "}\n",
    "val_map_rev = {v: k for k, v in val_map.items()}\n",
    "# df_redo['value_name'].unique()\n",
    "with open(\"batch_other_vals_o3.jsonl\", \"r\") as f:\n",
    "    with open(\"batch_other_vals_o3_failed_2.jsonl\", \"w\") as f_out:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            pid, domain, reap_id, val = json.loads(line)['custom_id'].split(\"-\") \n",
    "            val = val_map_rev[val] if val in val_map_rev else val\n",
    "            if not df_redo.loc[(df_redo['reap_id'] == int(reap_id)) & (df_redo['value_name'] == val)].empty:\n",
    "                f_out.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submit failed lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-N34eP5VtECgkCTqwt8KNfH', bytes=287316, created_at=1739667147, filename='batch_other_vals_o3_failed_2.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67b136cd343c8190b5dc626df2d99694', completion_window='24h', created_at=1739667149, endpoint='/v1/chat/completions', input_file_id='file-N34eP5VtECgkCTqwt8KNfH', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1739753549, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines 2 - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read and split the original file\n",
    "file_path = \"batch_other_vals_o3_failed_2.jsonl\"\n",
    "chunks = read_and_split_jsonl(file_path)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} - vbbr_bot_streamlit failed lines 2 - other_vals_o3\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve redone lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_67b381158a388190be45c51350f41244', completion_window='24h', created_at=1739817237, endpoint='/v1/chat/completions', input_file_id='file-C4i1tXJgjxDHFQtpJ3nh4o', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1739817515, error_file_id=None, errors=None, expired_at=None, expires_at=1739903637, failed_at=None, finalizing_at=1739817508, in_progress_at=1739817238, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines 3 - other_vals_o3'}, output_file_id='file-4u7DbVjuPztQNwiNruxgWa', request_counts=BatchRequestCounts(completed=44, failed=0, total=44)),\n",
       " Batch(id='batch_67b136cd343c8190b5dc626df2d99694', completion_window='24h', created_at=1739667149, endpoint='/v1/chat/completions', input_file_id='file-N34eP5VtECgkCTqwt8KNfH', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1739668209, error_file_id='file-53SmLVNCLhPNNPoAp6etTZ', errors=None, expired_at=None, expires_at=1739753549, failed_at=None, finalizing_at=1739668197, in_progress_at=1739667150, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines 2 - other_vals_o3'}, output_file_id='file-TyaZrW9fzsy55rvF8CNfTw', request_counts=BatchRequestCounts(completed=133, failed=2, total=135)),\n",
       " Batch(id='batch_67ab9622736c819085007114cdc811cb', completion_window='24h', created_at=1739298338, endpoint='/v1/chat/completions', input_file_id='file-WKUysKYLdbtqex3YdtyyB7', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1739309927, error_file_id=None, errors=None, expired_at=None, expires_at=1739384738, failed_at=None, finalizing_at=1739309679, in_progress_at=1739298341, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id='file-P8nrnzZEAbaEnPTkFzRxGZ', request_counts=BatchRequestCounts(completed=2709, failed=0, total=2709)),\n",
       " Batch(id='batch_67ab938d9e888190b6c6340480e408d2', completion_window='24h', created_at=1739297677, endpoint='/v1/chat/completions', input_file_id='file-RwDGW1TXuzBVJqH6n5CnWw', object='batch', status='cancelled', cancelled_at=1739298447, cancelling_at=1739297787, completed_at=None, error_file_id='file-UWXbCCPtLydspKXAD6vvtD', errors=None, expired_at=None, expires_at=1739384077, failed_at=None, finalizing_at=None, in_progress_at=1739297678, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=2709)),\n",
       " Batch(id='batch_67a53a475ed48190b8d6a055a3ce7b70', completion_window='24h', created_at=1738881607, endpoint='/v1/chat/completions', input_file_id='file-4jp7cXm8rUrD27ogiFbTsM', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738890869, error_file_id=None, errors=None, expired_at=None, expires_at=1738968007, failed_at=None, finalizing_at=1738889026, in_progress_at=1738881614, metadata={'description': 'Chunk 1 - reappraisal_intervention_clarity - schwartz_values_o3'}, output_file_id='file-E9pEZLTZUmixxZp8gXq8eW', request_counts=BatchRequestCounts(completed=11420, failed=0, total=11420)),\n",
       " Batch(id='batch_67a530e71d588190b754d20b987f7405', completion_window='24h', created_at=1738879207, endpoint='/v1/chat/completions', input_file_id='file-C7PqFzJquDe8qr3g8SXWEZ', object='batch', status='cancelled', cancelled_at=1738882847, cancelling_at=1738880706, completed_at=None, error_file_id='file-FbKpBSRF2zJc1yysaFRPJX', errors=None, expired_at=None, expires_at=1738965607, failed_at=None, finalizing_at=None, in_progress_at=1738879216, metadata={'description': 'Chunk 1 - reappraisal_intervention_clarity - other_vals_o3'}, output_file_id='file-7bXz2J4FHWmPZeDn36Q9dH', request_counts=BatchRequestCounts(completed=2567, failed=0, total=36544))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# client.batches.cancel(\"batch_abc123\")\n",
    "openai_files = client.batches.list(limit=6).data\n",
    "openai_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "file_id = \"file-TyaZrW9fzsy55rvF8CNfTw\"\n",
    "data = [\n",
    "    (client.files.content(file_id).text, \"3\")\n",
    "]\n",
    "\n",
    "# write to json\n",
    "with open(\"batch_other_vals_o3_failed_2_output.jsonl\", \"w\") as f_out:\n",
    "    for i, (text, num) in enumerate(data):\n",
    "        f_out.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def convert_batch_output_to_pd(raw_data, batch_num):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'batch_num': batch_num,\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    df['code'] = df['code'].str.extract(r'(\\d)')\n",
    "    df['code'] = df['code'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_other_vals_coding_failed = pd.concat([convert_batch_output_to_pd(data[i][0], data[i][1]) for i in range(len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_vals_coding_failed.to_csv(\"df_other_vals_coding_failed_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo failed lines 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['66614c693d129e9d6e6bfa10-relationship-230-growth',\n",
       "       '66a398080da27efcc3e8ecef-career-497-success',\n",
       "       '5d9b5e2d8465bf02e1190626-relationship-562-interpersonal_harmony',\n",
       "       '60b76ee2219ac1ce25ccea43-relationship-427-benevolence',\n",
       "       '665cbb56d9ecb20564b9b607-career-265-stability',\n",
       "       '665cbb56d9ecb20564b9b607-career-261-health',\n",
       "       '66614c693d129e9d6e6bfa10-career-308-drive',\n",
       "       '669dd09b9f38ff047dce18b0-relationship-340-interpersonal_harmony',\n",
       "       '66ac140ffbe9e717e0d21357-relationship-342-benevolence',\n",
       "       '670170d009f9a820a5d1e654-relationship-774-health',\n",
       "       '64d50a995a3627ba7ebeccb7-relationship-489-collaboration',\n",
       "       '662a05cb8d07939ee23e41a4-relationship-437-connection',\n",
       "       '65172a5accd4f7b31d650d6f-relationship-1099-community',\n",
       "       '671b563f47fb11fe5e685f43-career-1590-connection',\n",
       "       '5dd352c51c219b35931aefd1-career-1023-collaboration',\n",
       "       '67374b226c6050f8e53e8c27-relationship-1054-perseverance',\n",
       "       '65b98fe25e75b5acc3f44626-career-1537-health',\n",
       "       '668f8d7343028ae0faa7a907-career-1196-health',\n",
       "       '671fca7287fb225453006af0-career-1181-success',\n",
       "       '64060f1213c5c70c63c18b96-relationship-1432-health',\n",
       "       '66a218f455df3fda0c1230c1-relationship-1908-drive',\n",
       "       '673577b7a8bbd1bf5737afe1-relationship-1490-collaboration',\n",
       "       '66ba8d4d55cc58fac2423e5e-career-1340-connection',\n",
       "       '64509bfcd8d8b7e61f801e95-relationship-2000-collaboration',\n",
       "       '6509a4f9b4beb6a04abd0d7c-career-1871-perseverance',\n",
       "       '6509a4f9b4beb6a04abd0d7c-career-1867-competency',\n",
       "       '603f28793a28f30ab6932a12-career-1918-benevolence',\n",
       "       '65b929230cff388d15dd5c4c-relationship-1981-pleasure',\n",
       "       '64509bfcd8d8b7e61f801e95-career-2058-interpersonal_harmony',\n",
       "       '64417871875bc046c888c152-relationship-2121-health',\n",
       "       '611c2ed2d1d6a90e05ceeb30-career-2311-creativity',\n",
       "       '6692d19a89c0d9d85c058647-career-2313-perseverance',\n",
       "       '5f1db15b22c07d01e51960ad-relationship-2330-interpersonal_harmony',\n",
       "       '5be9ce784f251d00015ce92e-career-2320-interpersonal_harmony',\n",
       "       '5dee8ee31255595293a9906b-relationship-2612-interpersonal_harmony',\n",
       "       '56802e5fc5767f00121cc6a0-career-2624-success',\n",
       "       '623519c893eaebfcb0046e26-relationship-3079-success',\n",
       "       '5dd9b725954d19948f95327c-relationship-2646-perseverance',\n",
       "       '667434ac57d06c90c3261d5c-relationship-2656-health',\n",
       "       '66a7dbfbc78674868afa3b59-relationship-2985-community',\n",
       "       '66828964434e3570607d323d-relationship-2994-pleasure',\n",
       "       '671aac78fe2a45db746d3d5f-relationship-3150-family',\n",
       "       '66639f08a4e81235c3d7a659-relationship-3185-community',\n",
       "       '5c1ebf5f658e9200017ae7e9-relationship-3153-connection'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = pd.read_csv(\"~/Downloads/tmpsladkfjas.csv\")\n",
    "failed_ids = df_tmp['custom_id'].values\n",
    "failed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"batch_other_vals_o3.jsonl\"\n",
    "new_file_path = \"batch_other_vals_o3_failed_3.jsonl\"\n",
    "# filter lines where the custom_id is in the failed_ids and write to new json\n",
    "with open(file_path, \"r\") as f_in, open(new_file_path, \"w\") as f_out:\n",
    "    for line in f_in:\n",
    "        data = json.loads(line)\n",
    "        if data['custom_id'] in failed_ids:\n",
    "            # remove data['body']['max_completion_tokens']\n",
    "            del data['body']['max_completion_tokens']\n",
    "            f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-C4i1tXJgjxDHFQtpJ3nh4o', bytes=92791, created_at=1739817236, filename='batch_other_vals_o3_failed_3.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67b381158a388190be45c51350f41244', completion_window='24h', created_at=1739817237, endpoint='/v1/chat/completions', input_file_id='file-C4i1tXJgjxDHFQtpJ3nh4o', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1739903637, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit failed lines 3 - other_vals_o3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to read and split the JSONL file into chunks of 50k lines\n",
    "def read_and_split_jsonl(file_path, max_lines=50000):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Split the lines into chunks of max_lines\n",
    "    chunks = [lines[i:i + max_lines] for i in range(0, len(lines), max_lines)]\n",
    "    return chunks\n",
    "\n",
    "# Read and split the original file\n",
    "file_path = new_file_path\n",
    "chunks = read_and_split_jsonl(file_path)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} - vbbr_bot_streamlit failed lines 3 - other_vals_o3\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "file_id = \"file-4u7DbVjuPztQNwiNruxgWa\"\n",
    "data = [\n",
    "    (client.files.content(file_id).text, \"4\")\n",
    "]\n",
    "\n",
    "# write to json\n",
    "with open(\"batch_other_vals_o3_failed_3_output.jsonl\", \"w\") as f_out:\n",
    "    for i, (text, num) in enumerate(data):\n",
    "        f_out.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def convert_batch_output_to_pd(raw_data, batch_num):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'batch_num': batch_num,\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    df['code'] = df['code'].str.extract(r'(\\d)')\n",
    "    df['code'] = df['code'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_other_vals_coding_failed = pd.concat([convert_batch_output_to_pd(data[i][0], data[i][1]) for i in range(len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_vals_coding_failed.to_csv(\"df_other_vals_coding_failed_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schwartz batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_schwartz = \"\"\"\n",
    "<ignore>{salt}</ignore>\n",
    "\n",
    "Your task is to determine whether a given cognitive reappraisal for an issue reflects the value of {value}. \n",
    "A value is only incorporated if the active ingredient of the reappraisal, i.e., the crux of what helps someone feel better, revolves around the value of {value}.\n",
    "\n",
    "Very briefly (1-3 sentences) walk through your thought process about whether the reappraisal centers on the value of {value} and then ultimately decide whether it does or not by responding with one of the following codes:\n",
    "\n",
    "- `Code[1]` for yes\n",
    "- `Code[0]` for no\n",
    "\n",
    "Be sure to format your response as `Code[1]` or `Code[0]` at the end of your response formatted just like that after walking through your thought process.\n",
    "\n",
    "Issue: {issue}\n",
    "Reappraisal: {reappraisal}\n",
    "\n",
    "Does this cognitive reappraisal center on the value of {value}? \n",
    "\n",
    "{description}\n",
    "\n",
    "Be conservative with your answers. Only respond with `Code[1]` if the active ingredient of the given cognitive reappraisal centers around the value of {value} as described above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"batch_schwartz.jsonl\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for _, row in df_issues_reaps.iterrows():\n",
    "        for val in schwartz_list:\n",
    "            value_name = val['name']\n",
    "            description = val['description']\n",
    "            \n",
    "            # Extract needed fields\n",
    "            pid = row['participant_id']\n",
    "            domain = row['domain']\n",
    "            reap_id = row['id']             # The \"id\" column from your reappraisal df\n",
    "            issue = row['summary']\n",
    "            reappraisal = row['text']\n",
    "\n",
    "            # Generate a random salt\n",
    "            salt = os.urandom(8).hex()\n",
    "\n",
    "            # Format the system prompt\n",
    "            system_prompt = prompt_schwartz.format(\n",
    "                salt=salt,\n",
    "                value=value_name,\n",
    "                issue=issue,\n",
    "                reappraisal=reappraisal,\n",
    "                description=description\n",
    "            )\n",
    "\n",
    "            # Construct the JSON for each line\n",
    "            value_name_clean = value_name.replace(\" \", \"_\").lower()\n",
    "            value_name_clean = value_name_clean.replace(\"-\", \"_\")\n",
    "            data = {\n",
    "                \"custom_id\": f\"{pid}-{domain}-{reap_id}-{value_name_clean}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": MODEL,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": system_prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    \"temperature\": TEMP,\n",
    "                    \"max_tokens\": 120,\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Write each request as one line of JSON\n",
    "            f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-12yNGJyxJRx9B1SFAsqDYW', bytes=58402876, created_at=1736980215, filename='batch_schwartz.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_678836f96e648190a7177930cc16dc26', completion_window='24h', created_at=1736980217, endpoint='/v1/chat/completions', input_file_id='file-12yNGJyxJRx9B1SFAsqDYW', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1737066617, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 of batch processing - schwartz'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to read and split the JSONL file into chunks of 50k lines\n",
    "def read_and_split_jsonl(file_path, max_lines=50000):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Split the lines into chunks of max_lines\n",
    "    chunks = [lines[i:i + max_lines] for i in range(0, len(lines), max_lines)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Read and split the original file\n",
    "file_path = \"batch_schwartz.jsonl\"\n",
    "chunks = read_and_split_jsonl(file_path)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} of batch processing - schwartz\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belief batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create belief submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_primals = \"\"\"\n",
    "# <ignore>{salt}</ignore>\n",
    "\n",
    "# Your task is to determine whether a given cognitive reappraisal for an issue reflects the belief that the world is {belief}. \n",
    "\n",
    "# Very briefly (1-3 sentences) walk through your thought process about whether the reappraisal reflects the belief that the world is {belief} and then ultimately decide whether it does or not by responding with one of the following codes:\n",
    "\n",
    "# - `Code[1]` for yes\n",
    "# - `Code[0]` for no\n",
    "\n",
    "# Be sure to format your response as `Code[1]` or `Code[0]` at the end of your response formatted just like that after walking through your thought process.\n",
    "\n",
    "# Issue: {issue}\n",
    "# Reappraisal: {reappraisal}\n",
    "\n",
    "# Does this cognitive reappraisal reflect the belief that the world is {belief}? \n",
    "\n",
    "# Believing that the world is {belief} is defined as follows:\n",
    "# {description}\n",
    "\n",
    "# Be conservative with your answers. Only respond with `Code[1]` if the active ingredient of the given cognitive reappraisal very clearly and explicitly reflects the belief that the world is {belief} as defined above.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "prompt_primals_o3 = \"\"\"\n",
    "<ignore>{salt}</ignore>\n",
    "\n",
    "Your task is to determine whether a given cognitive reappraisal for an issue incorporates the belief that the world is {belief}. \n",
    "\n",
    "<{belief}-belief-definition> {description} </{belief}-belief-definition>\n",
    "\n",
    "A reappraisal reflects the belief that the world is {belief} if its main emotional relief or active ingredient specifically rests on viewing this single situation as an example that the world is, in essence, {belief}. Its enough to show that the reappraisal treats this particular situation as evidence or an instantiation of the broader outlook that the world is {belief}, even if it does not claim the entire world is always that way.\n",
    "\n",
    "\n",
    "Indicate whether the belief is or is not incorporated in the reappraisal by responding with one of the following codes:\n",
    "\n",
    "- `Code[1]` for yes\n",
    "- `Code[0]` for no\n",
    "\n",
    "Be sure to format your response as `Code[1]` or `Code[0]`.\n",
    "\n",
    "<issue> {issue} </issue>\n",
    "<reappraisal> {reappraisal} </reappraisal>\n",
    "\n",
    "Be conservative with your answers. Only respond with `Code[1]` if the active ingredient of the given cognitive reappraisal clearly and explicitly is evidence for the view that the world is {belief} as described above. Otherwise, respond with `Code[0]`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "batch_primals_submission_fpath = f\"batch_primals_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.jsonl\"\n",
    "with open(batch_primals_submission_fpath, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for _, row in df_issues_reaps.iterrows():\n",
    "        for b in belief_list:\n",
    "            belief_name = b['name']\n",
    "            description = b['description']\n",
    "            \n",
    "            # Extract needed fields\n",
    "            pid = row['participant_id']\n",
    "            domain = row['domain']\n",
    "            reap_id = row['id']             # The \"id\" column from your reappraisal df\n",
    "            issue = row['summary']\n",
    "            reappraisal = row['text']\n",
    "\n",
    "            # Generate a random salt\n",
    "            salt = os.urandom(2).hex()\n",
    "\n",
    "            # Format the system prompt\n",
    "            system_prompt = prompt_primals_o3.format(\n",
    "                salt=salt,\n",
    "                belief=belief_name,\n",
    "                issue=issue,\n",
    "                reappraisal=reappraisal,\n",
    "                description=description\n",
    "            )\n",
    "\n",
    "            # Construct the JSON for each line\n",
    "            belief_name_clean = belief_name.replace(\" \", \"_\").lower()\n",
    "            belief_name_clean = belief_name_clean.replace(\"-\", \"_\")\n",
    "            data = {\n",
    "                \"custom_id\": f\"{pid}-{domain}-{reap_id}-{belief_name_clean}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"o3-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": system_prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    \"reasoning_effort\": \"low\",\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Write each request as one line of JSON\n",
    "            f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-QXUTcXFYe9UJcpWpDyHUwA', bytes=117091986, created_at=1738801980, filename='batch_other_vals_o3.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67a40340be9c819087b8c1716b5f9259', completion_window='24h', created_at=1738801984, endpoint='/v1/chat/completions', input_file_id='file-QXUTcXFYe9UJcpWpDyHUwA', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1738888384, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 vbbr_bot_streamlit - primals - o3mini'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "FileObject(id='file-VLb71KHTi1JU3pjeq8uVX5', bytes=47268446, created_at=1738801987, filename='batch_other_vals_o3.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_67a40344cc348190adf4baab309b2cb4', completion_window='24h', created_at=1738801988, endpoint='/v1/chat/completions', input_file_id='file-VLb71KHTi1JU3pjeq8uVX5', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1738888388, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 2 vbbr_bot_streamlit - primals - o3mini'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to read and split the JSONL file into chunks of 50k lines\n",
    "def read_and_split_jsonl(file_path, max_lines=50000):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Split the lines into chunks of max_lines\n",
    "    chunks = [lines[i:i + max_lines] for i in range(0, len(lines), max_lines)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Read and split the original file\n",
    "chunks = read_and_split_jsonl(batch_primals_submission_fpath)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} vbbr_bot_streamlit - primals - o3mini\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_67a3a0370cf48190b208dc434801019f', completion_window='24h', created_at=1738776631, endpoint='/v1/chat/completions', input_file_id='file-7BcJ4sMpkCPUp87qubenr8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738789401, error_file_id='file-XYg1GRFsdkRn7wtZtdHHNF', errors=None, expired_at=None, expires_at=1738863031, failed_at=None, finalizing_at=1738786928, in_progress_at=1738776640, metadata={'description': 'Chunk 2 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-S8guhPkdw6mVrfSVKt2gBg', request_counts=BatchRequestCounts(completed=19688, failed=304, total=19992)),\n",
       " Batch(id='batch_67a3a01200ac8190ad287da58131b299', completion_window='24h', created_at=1738776594, endpoint='/v1/chat/completions', input_file_id='file-F2vnQPLGLHS3KB9BfjVaVg', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738797664, error_file_id='file-AZCh1S4RaGbPq5x6H18jWX', errors=None, expired_at=None, expires_at=1738862994, failed_at=None, finalizing_at=1738791590, in_progress_at=1738776677, metadata={'description': 'Chunk 1 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-MtKP9AyneSKxVrgt4q36b8', request_counts=BatchRequestCounts(completed=49243, failed=757, total=50000)),\n",
       " Batch(id='batch_67a2f70f8fec81908e650e8ce8dfb665', completion_window='24h', created_at=1738733327, endpoint='/v1/chat/completions', input_file_id='file-5ttqjL32yVMLKeRFvfVE5o', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738759645, error_file_id='file-CB4f8t8p1DMLQc7rG7qWPj', errors=None, expired_at=None, expires_at=1738819727, failed_at=None, finalizing_at=1738753508, in_progress_at=1738733342, metadata={'description': 'Chunk 2 - vbbr_bot_streamlit - other_vals_o3'}, output_file_id='file-QadV6TJE3ZCB6AT9rKsD7N', request_counts=BatchRequestCounts(completed=36089, failed=55, total=36144)),\n",
       " Batch(id='batch_67a2f6d456f48190b250694d308a9d12', completion_window='24h', created_at=1738733268, endpoint='/v1/chat/completions', input_file_id='file-TVQzLMbWnpKv7wc2we97uD', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738762174, error_file_id='file-TS6B9mT9xbXvkT8hHWGTQ7', errors=None, expired_at=None, expires_at=1738819668, failed_at=None, finalizing_at=1738754000, in_progress_at=1738733287, metadata={'description': 'Chunk 1 - vbbr_bot_streamlit - other_vals_o3'}, output_file_id='file-2LsupYC8AwH7mJiMrF3E8E', request_counts=BatchRequestCounts(completed=49911, failed=89, total=50000)),\n",
       " Batch(id='batch_67a0224ae1f88190ad2c931ea9c4f29a', completion_window='24h', created_at=1738547787, endpoint='/v1/chat/completions', input_file_id='file-BAvzuG3PcCJ7gg1a6dgagM', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738557853, error_file_id=None, errors=None, expired_at=None, expires_at=1738634187, failed_at=None, finalizing_at=1738555721, in_progress_at=1738547793, metadata={'description': 'vbr congruence pvq - chunk 1 - othervals og - batch 0'}, output_file_id='file-812YZJuD3GGMRvgEsRnEWX', request_counts=BatchRequestCounts(completed=20091, failed=0, total=20091)),\n",
       " Batch(id='batch_67a016ebedb4819083facda2c713e464', completion_window='24h', created_at=1738544876, endpoint='/v1/chat/completions', input_file_id='file-3GvhJnFhhVa6cSUcYbwBqw', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738554425, error_file_id=None, errors=None, expired_at=None, expires_at=1738631276, failed_at=None, finalizing_at=1738552065, in_progress_at=1738544882, metadata={'description': 'Chunk 1 of batch processing - careervals 4o - batch 0'}, output_file_id='file-QE41VRVzTpwFRYK1sEyCrv', request_counts=BatchRequestCounts(completed=15048, failed=0, total=15048))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# client.batches.cancel(\"batch_abc123\")\n",
    "openai_files = client.batches.list(limit=6).data\n",
    "openai_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feb 5\n",
    "primals_1a_file_id = \"file-MtKP9AyneSKxVrgt4q36b8\"\n",
    "primals_1b_file_id = \"file-S8guhPkdw6mVrfSVKt2gBg\"\n",
    "data = [\n",
    "    (client.files.content(primals_1a_file_id).text, \"1a\"),\n",
    "    (client.files.content(primals_1b_file_id).text, \"1b\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_batch_output_to_pd(raw_data, batch_num):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'batch_num': batch_num,\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    df['code'] = df['code'].str.extract(r'(\\d)')\n",
    "    df['code'] = df['code'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_primals_coding = pd.concat([convert_batch_output_to_pd(data[i][0], data[i][1]) for i in range(len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primals_coding.to_csv(\"df_primals_coding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_67a40344cc348190adf4baab309b2cb4', completion_window='24h', created_at=1738801988, endpoint='/v1/chat/completions', input_file_id='file-VLb71KHTi1JU3pjeq8uVX5', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738809198, error_file_id=None, errors=None, expired_at=None, expires_at=1738888388, failed_at=None, finalizing_at=1738807730, in_progress_at=1738801994, metadata={'description': 'Chunk 2 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-XtzeW1rw6yS4tAnJecQwtQ', request_counts=BatchRequestCounts(completed=19992, failed=0, total=19992)),\n",
       " Batch(id='batch_67a40340be9c819087b8c1716b5f9259', completion_window='24h', created_at=1738801984, endpoint='/v1/chat/completions', input_file_id='file-QXUTcXFYe9UJcpWpDyHUwA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738822443, error_file_id=None, errors=None, expired_at=None, expires_at=1738888384, failed_at=None, finalizing_at=1738816791, in_progress_at=1738801997, metadata={'description': 'Chunk 1 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-4BsptATkWcHWSdq8f7xK1T', request_counts=BatchRequestCounts(completed=50000, failed=0, total=50000)),\n",
       " Batch(id='batch_67a3a0370cf48190b208dc434801019f', completion_window='24h', created_at=1738776631, endpoint='/v1/chat/completions', input_file_id='file-7BcJ4sMpkCPUp87qubenr8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738789401, error_file_id='file-XYg1GRFsdkRn7wtZtdHHNF', errors=None, expired_at=None, expires_at=1738863031, failed_at=None, finalizing_at=1738786928, in_progress_at=1738776640, metadata={'description': 'Chunk 2 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-S8guhPkdw6mVrfSVKt2gBg', request_counts=BatchRequestCounts(completed=19688, failed=304, total=19992)),\n",
       " Batch(id='batch_67a3a01200ac8190ad287da58131b299', completion_window='24h', created_at=1738776594, endpoint='/v1/chat/completions', input_file_id='file-F2vnQPLGLHS3KB9BfjVaVg', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738797664, error_file_id='file-AZCh1S4RaGbPq5x6H18jWX', errors=None, expired_at=None, expires_at=1738862994, failed_at=None, finalizing_at=1738791590, in_progress_at=1738776677, metadata={'description': 'Chunk 1 vbbr_bot_streamlit - primals - o3mini'}, output_file_id='file-MtKP9AyneSKxVrgt4q36b8', request_counts=BatchRequestCounts(completed=49243, failed=757, total=50000)),\n",
       " Batch(id='batch_67a2f70f8fec81908e650e8ce8dfb665', completion_window='24h', created_at=1738733327, endpoint='/v1/chat/completions', input_file_id='file-5ttqjL32yVMLKeRFvfVE5o', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738759645, error_file_id='file-CB4f8t8p1DMLQc7rG7qWPj', errors=None, expired_at=None, expires_at=1738819727, failed_at=None, finalizing_at=1738753508, in_progress_at=1738733342, metadata={'description': 'Chunk 2 - vbbr_bot_streamlit - other_vals_o3'}, output_file_id='file-QadV6TJE3ZCB6AT9rKsD7N', request_counts=BatchRequestCounts(completed=36089, failed=55, total=36144))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# client.batches.cancel(\"batch_abc123\")\n",
    "openai_files = client.batches.list(limit=5).data\n",
    "openai_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feb 5\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "primals_1_file_id = \"file-4BsptATkWcHWSdq8f7xK1T\"\n",
    "primals_2_file_id = \"file-XtzeW1rw6yS4tAnJecQwtQ\"\n",
    "data = [\n",
    "    (client.files.content(primals_1_file_id).text, \"1a\"),\n",
    "    (client.files.content(primals_2_file_id).text, \"1b\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_batch_output_to_pd(raw_data, batch_num):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'batch_num': batch_num,\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    df['code'] = df['code'].str.extract(r'(\\d)')\n",
    "    df['code'] = df['code'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_primals_coding = pd.concat([convert_batch_output_to_pd(data[i][0], data[i][1]) for i in range(len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primals_coding.to_csv(\"df_primals_coding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve processed files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_issues_merge = pd.read_csv('../data/raw/sql_export/issues.csv')\n",
    "df_issues_merge = df_issues_merge.rename(columns={'id': 'issue_id', 'summary': 'issue_summary'})\n",
    "df_issues_merge = df_issues_merge[['issue_id', 'issue_summary']]\n",
    "\n",
    "df_reaps_merge = pd.read_csv('../data/raw/sql_export/reappraisals.csv')\n",
    "df_reaps_merge = df_reaps_merge.rename(columns={'id': 'reap_id', 'text': 'reap_text'})\n",
    "df_reaps_merge = df_reaps_merge[['reap_id', 'issue_id', 'reap_text']]\n",
    "\n",
    "def convert_batch_output_to_pd(raw_data):\n",
    "\n",
    "    # Split the data into separate JSON strings\n",
    "    json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "    # Parse the JSON objects\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    # Extract relevant fields\n",
    "    extracted_data = []\n",
    "    for item in parsed_data:\n",
    "        response_body = item['response']['body']\n",
    "        usage = response_body['usage']\n",
    "        choice = response_body['choices'][0]\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'batch_id': item['id'],\n",
    "            'custom_id': item['custom_id'],\n",
    "            'status_code': item['response']['status_code'],\n",
    "            'request_id': item['response']['request_id'],\n",
    "            'completion_id': response_body['id'],\n",
    "            'model': response_body['model'],\n",
    "            'created': response_body['created'],\n",
    "            'assistant_message': choice['message']['content'],\n",
    "            'finish_reason': choice['finish_reason'],\n",
    "            'prompt_tokens': usage['prompt_tokens'],\n",
    "            'completion_tokens': usage['completion_tokens'],\n",
    "            'total_tokens': usage['total_tokens'],\n",
    "            'system_fingerprint': response_body['system_fingerprint']\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "    df['reap_id'] = df['reap_id'].astype(int)\n",
    "    df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "    # merge reaps\n",
    "    df = df.merge(df_reaps_merge, left_on='reap_id', right_on='reap_id', how='left')\n",
    "    # merge issues\n",
    "    df = df.merge(df_issues_merge, left_on='issue_id', right_on='issue_id', how='left')\n",
    "    # df['code'] = df['code'].astype(int)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "primals_dfs = []\n",
    "for i, data in enumerate([primals_1, primals_2]):\n",
    "    data = data.text\n",
    "    df = convert_batch_output_to_pd(data)\n",
    "    df['batch'] = i + 1\n",
    "    primals_dfs.append(df)\n",
    "    \n",
    "values_dfs = []\n",
    "for i, data in enumerate([values_1, values_2, values_3]):\n",
    "    data = data.text\n",
    "    df = convert_batch_output_to_pd(data)\n",
    "    df['batch'] = i + 1\n",
    "    values_dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>status_code</th>\n",
       "      <th>request_id</th>\n",
       "      <th>completion_id</th>\n",
       "      <th>model</th>\n",
       "      <th>created</th>\n",
       "      <th>assistant_message</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>system_fingerprint</th>\n",
       "      <th>pid</th>\n",
       "      <th>domain</th>\n",
       "      <th>reap_id</th>\n",
       "      <th>dimension</th>\n",
       "      <th>code</th>\n",
       "      <th>issue_id</th>\n",
       "      <th>reap_text</th>\n",
       "      <th>issue_summary</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_677f852bf31481909d6d286f73a10f6d</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e-relationship-189-abun...</td>\n",
       "      <td>200</td>\n",
       "      <td>36ad074f307f9c2c460c77c8a2690e8b</td>\n",
       "      <td>chatcmpl-AnfjmXV9Oe79x5Tqs7Z35bDB388mo</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>1736401874</td>\n",
       "      <td>The reappraisal emphasizes the excitement and ...</td>\n",
       "      <td>stop</td>\n",
       "      <td>347</td>\n",
       "      <td>...</td>\n",
       "      <td>fp_703d4ff298</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e</td>\n",
       "      <td>relationship</td>\n",
       "      <td>189</td>\n",
       "      <td>abundant</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>Sometimes, the anticipation and imagination of...</td>\n",
       "      <td>You want to expand your friend group to includ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_677f852c217881908da67f4c0636e5eb</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e-relationship-189-acce...</td>\n",
       "      <td>200</td>\n",
       "      <td>9e7381e1c9f324d6f5d0d9611ee84f5d</td>\n",
       "      <td>chatcmpl-AnfjmJ7XiZ7t76KxU3LYdu732dlaJ</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>1736401874</td>\n",
       "      <td>The reappraisal focuses on the excitement and ...</td>\n",
       "      <td>stop</td>\n",
       "      <td>344</td>\n",
       "      <td>...</td>\n",
       "      <td>fp_b7d65f1a5b</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e</td>\n",
       "      <td>relationship</td>\n",
       "      <td>189</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Sometimes, the anticipation and imagination of...</td>\n",
       "      <td>You want to expand your friend group to includ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_677f852c598881908ec44d762562ac1a</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e-relationship-189-beau...</td>\n",
       "      <td>200</td>\n",
       "      <td>41602ae44bb85f5994ce86dc2f26854c</td>\n",
       "      <td>chatcmpl-Anfjm3TdHf5Zk5pXoafQ7WzIZ3Dmt</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>1736401874</td>\n",
       "      <td>The reappraisal focuses on the excitement and ...</td>\n",
       "      <td>stop</td>\n",
       "      <td>365</td>\n",
       "      <td>...</td>\n",
       "      <td>fp_b7d65f1a5b</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e</td>\n",
       "      <td>relationship</td>\n",
       "      <td>189</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Sometimes, the anticipation and imagination of...</td>\n",
       "      <td>You want to expand your friend group to includ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_677f852c87008190863f83a7cbec7554</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e-relationship-189-chan...</td>\n",
       "      <td>200</td>\n",
       "      <td>0d4a987fa05b19aeb574734205516c3f</td>\n",
       "      <td>chatcmpl-AnfjmEP6aVkvLZfFwkhu2NzGOSQaU</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>1736401874</td>\n",
       "      <td>The cognitive reappraisal focuses on the excit...</td>\n",
       "      <td>stop</td>\n",
       "      <td>392</td>\n",
       "      <td>...</td>\n",
       "      <td>fp_703d4ff298</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e</td>\n",
       "      <td>relationship</td>\n",
       "      <td>189</td>\n",
       "      <td>changing</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Sometimes, the anticipation and imagination of...</td>\n",
       "      <td>You want to expand your friend group to includ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_677f852cac3c81908db0ff84cbdfe3c1</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e-relationship-189-coop...</td>\n",
       "      <td>200</td>\n",
       "      <td>05aae834fa8bd3f39a0a11919fe260e7</td>\n",
       "      <td>chatcmpl-Anfjm5gSiJ3dXkYvpWH0z5fxTEV2L</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>1736401874</td>\n",
       "      <td>The reappraisal emphasizes the excitement and ...</td>\n",
       "      <td>stop</td>\n",
       "      <td>344</td>\n",
       "      <td>...</td>\n",
       "      <td>fp_5f20662549</td>\n",
       "      <td>601f5a82dc8ed94a9da4461e</td>\n",
       "      <td>relationship</td>\n",
       "      <td>189</td>\n",
       "      <td>cooperative</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Sometimes, the anticipation and imagination of...</td>\n",
       "      <td>You want to expand your friend group to includ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     batch_id  \\\n",
       "0  batch_req_677f852bf31481909d6d286f73a10f6d   \n",
       "1  batch_req_677f852c217881908da67f4c0636e5eb   \n",
       "2  batch_req_677f852c598881908ec44d762562ac1a   \n",
       "3  batch_req_677f852c87008190863f83a7cbec7554   \n",
       "4  batch_req_677f852cac3c81908db0ff84cbdfe3c1   \n",
       "\n",
       "                                           custom_id  status_code  \\\n",
       "0  601f5a82dc8ed94a9da4461e-relationship-189-abun...          200   \n",
       "1  601f5a82dc8ed94a9da4461e-relationship-189-acce...          200   \n",
       "2  601f5a82dc8ed94a9da4461e-relationship-189-beau...          200   \n",
       "3  601f5a82dc8ed94a9da4461e-relationship-189-chan...          200   \n",
       "4  601f5a82dc8ed94a9da4461e-relationship-189-coop...          200   \n",
       "\n",
       "                         request_id                           completion_id  \\\n",
       "0  36ad074f307f9c2c460c77c8a2690e8b  chatcmpl-AnfjmXV9Oe79x5Tqs7Z35bDB388mo   \n",
       "1  9e7381e1c9f324d6f5d0d9611ee84f5d  chatcmpl-AnfjmJ7XiZ7t76KxU3LYdu732dlaJ   \n",
       "2  41602ae44bb85f5994ce86dc2f26854c  chatcmpl-Anfjm3TdHf5Zk5pXoafQ7WzIZ3Dmt   \n",
       "3  0d4a987fa05b19aeb574734205516c3f  chatcmpl-AnfjmEP6aVkvLZfFwkhu2NzGOSQaU   \n",
       "4  05aae834fa8bd3f39a0a11919fe260e7  chatcmpl-Anfjm5gSiJ3dXkYvpWH0z5fxTEV2L   \n",
       "\n",
       "               model     created  \\\n",
       "0  gpt-4o-2024-08-06  1736401874   \n",
       "1  gpt-4o-2024-08-06  1736401874   \n",
       "2  gpt-4o-2024-08-06  1736401874   \n",
       "3  gpt-4o-2024-08-06  1736401874   \n",
       "4  gpt-4o-2024-08-06  1736401874   \n",
       "\n",
       "                                   assistant_message finish_reason  \\\n",
       "0  The reappraisal emphasizes the excitement and ...          stop   \n",
       "1  The reappraisal focuses on the excitement and ...          stop   \n",
       "2  The reappraisal focuses on the excitement and ...          stop   \n",
       "3  The cognitive reappraisal focuses on the excit...          stop   \n",
       "4  The reappraisal emphasizes the excitement and ...          stop   \n",
       "\n",
       "   prompt_tokens  ...  system_fingerprint                       pid  \\\n",
       "0            347  ...       fp_703d4ff298  601f5a82dc8ed94a9da4461e   \n",
       "1            344  ...       fp_b7d65f1a5b  601f5a82dc8ed94a9da4461e   \n",
       "2            365  ...       fp_b7d65f1a5b  601f5a82dc8ed94a9da4461e   \n",
       "3            392  ...       fp_703d4ff298  601f5a82dc8ed94a9da4461e   \n",
       "4            344  ...       fp_5f20662549  601f5a82dc8ed94a9da4461e   \n",
       "\n",
       "         domain reap_id    dimension  code issue_id  \\\n",
       "0  relationship     189     abundant     1      102   \n",
       "1  relationship     189   acceptable     0      102   \n",
       "2  relationship     189    beautiful     0      102   \n",
       "3  relationship     189     changing     0      102   \n",
       "4  relationship     189  cooperative     0      102   \n",
       "\n",
       "                                           reap_text  \\\n",
       "0  Sometimes, the anticipation and imagination of...   \n",
       "1  Sometimes, the anticipation and imagination of...   \n",
       "2  Sometimes, the anticipation and imagination of...   \n",
       "3  Sometimes, the anticipation and imagination of...   \n",
       "4  Sometimes, the anticipation and imagination of...   \n",
       "\n",
       "                                       issue_summary batch  \n",
       "0  You want to expand your friend group to includ...     1  \n",
       "1  You want to expand your friend group to includ...     1  \n",
       "2  You want to expand your friend group to includ...     1  \n",
       "3  You want to expand your friend group to includ...     1  \n",
       "4  You want to expand your friend group to includ...     1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primals_df = pd.concat(primals_dfs)\n",
    "display(primals_df.head())\n",
    "# primals_df[\"custom_id\"].iloc[0]\n",
    "values_df = pd.concat(values_dfs)\n",
    "primals_df.to_csv(\"primals_coding_results.csv\", index=False)\n",
    "values_df.to_csv(\"values_coding_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>46</td>\n",
       "      <td>It's understandable to feel anxious about bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>47</td>\n",
       "      <td>Social interactions can be daunting, especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>48</td>\n",
       "      <td>Feeling awkward can lead to anxiety, but it ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>49</td>\n",
       "      <td>People treating you differently based on perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6632edd68127fba862de05bf</td>\n",
       "      <td>You experience social anxiety and feel easily ...</td>\n",
       "      <td>50</td>\n",
       "      <td>Networking and maintaining friendships might b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>relationship</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>You are experiencing problems with your attitu...</td>\n",
       "      <td>3200</td>\n",
       "      <td>When we struggle with expressing our emotions,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>relationship</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>You are experiencing problems with your attitu...</td>\n",
       "      <td>3201</td>\n",
       "      <td>Feeling out of control can be reframed as an i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>relationship</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>You are experiencing problems with your attitu...</td>\n",
       "      <td>3198</td>\n",
       "      <td>It's important to recognize that your awarenes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>relationship</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>You are experiencing problems with your attitu...</td>\n",
       "      <td>3202</td>\n",
       "      <td>Experiencing these conflicts might help you de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>relationship</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>You are experiencing problems with your attitu...</td>\n",
       "      <td>3199</td>\n",
       "      <td>Your emotions stemming from love suggest a dee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2692 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            domain            participant_id  \\\n",
       "0     relationship  6632edd68127fba862de05bf   \n",
       "1     relationship  6632edd68127fba862de05bf   \n",
       "2     relationship  6632edd68127fba862de05bf   \n",
       "3     relationship  6632edd68127fba862de05bf   \n",
       "4     relationship  6632edd68127fba862de05bf   \n",
       "...            ...                       ...   \n",
       "2687  relationship  66da38dc1d5b9365584508ca   \n",
       "2688  relationship  66da38dc1d5b9365584508ca   \n",
       "2689  relationship  66da38dc1d5b9365584508ca   \n",
       "2690  relationship  66da38dc1d5b9365584508ca   \n",
       "2691  relationship  66da38dc1d5b9365584508ca   \n",
       "\n",
       "                                                summary    id  \\\n",
       "0     You experience social anxiety and feel easily ...    46   \n",
       "1     You experience social anxiety and feel easily ...    47   \n",
       "2     You experience social anxiety and feel easily ...    48   \n",
       "3     You experience social anxiety and feel easily ...    49   \n",
       "4     You experience social anxiety and feel easily ...    50   \n",
       "...                                                 ...   ...   \n",
       "2687  You are experiencing problems with your attitu...  3200   \n",
       "2688  You are experiencing problems with your attitu...  3201   \n",
       "2689  You are experiencing problems with your attitu...  3198   \n",
       "2690  You are experiencing problems with your attitu...  3202   \n",
       "2691  You are experiencing problems with your attitu...  3199   \n",
       "\n",
       "                                                   text  \n",
       "0     It's understandable to feel anxious about bein...  \n",
       "1     Social interactions can be daunting, especiall...  \n",
       "2     Feeling awkward can lead to anxiety, but it ca...  \n",
       "3     People treating you differently based on perce...  \n",
       "4     Networking and maintaining friendships might b...  \n",
       "...                                                 ...  \n",
       "2687  When we struggle with expressing our emotions,...  \n",
       "2688  Feeling out of control can be reframed as an i...  \n",
       "2689  It's important to recognize that your awarenes...  \n",
       "2690  Experiencing these conflicts might help you de...  \n",
       "2691  Your emotions stemming from love suggest a dee...  \n",
       "\n",
       "[2692 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues_reaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "DIMS = 128\n",
    "\n",
    "# batch_embed_submission_fpath = f\"batch_{DIMS}_embeddings_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.jsonl\"\n",
    "batch_embed_submission_fpath = f\"batch_{DIMS}_embeddings.jsonl\"\n",
    "with open(batch_embed_submission_fpath, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for _, row in df_issues_reaps.iterrows():\n",
    "\n",
    "        # Extract needed fields\n",
    "        pid = row['participant_id']\n",
    "        domain = row['domain']\n",
    "        reap_id = row['id']\n",
    "        # issue = row['summary']\n",
    "        reappraisal = row['text']\n",
    "\n",
    "        # Construct the JSON for each line\n",
    "        data = {\n",
    "            \"custom_id\": f\"{pid}-{domain}-{reap_id}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/embeddings\",\n",
    "            \"body\": {\n",
    "                \"model\": \"text-embedding-3-small\",\n",
    "                \"input\": reappraisal,\n",
    "                \"dimensions\": DIMS\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Write each request as one line of JSON\n",
    "        f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-UteLs3hjhk6XLeyaQZwNDZ', bytes=1078710, created_at=1737342656, filename='batch_128_embeddings.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_678dbec3a8488190b81970310368aab3', completion_window='24h', created_at=1737342659, endpoint='/v1/embeddings', input_file_id='file-UteLs3hjhk6XLeyaQZwNDZ', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1737429059, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 of batch processing - embeddings'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to read and split the JSONL file into chunks of 50k lines\n",
    "def read_and_split_jsonl(file_path, max_lines=50000):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Split the lines into chunks of max_lines\n",
    "    chunks = [lines[i:i + max_lines] for i in range(0, len(lines), max_lines)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Read and split the original file\n",
    "chunks = read_and_split_jsonl(batch_embed_submission_fpath)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = batch_embed_submission_fpath  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/embeddings\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} of batch processing - embeddings\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_file_id = \"file-EM9qNrDQhLRGwgvgwmJJJu\"\n",
    "embeddings = client.files.content(embedding_file_id).text.strip().split('\\n')\n",
    "embeddings = [json.loads(emb) for emb in embeddings]\n",
    "# write to json\n",
    "with open(\"embeddings.json\", \"w\") as f:\n",
    "    json.dump(embeddings, f, indent=2)\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def convert_batch_output_to_pd(raw_data):\n",
    "\n",
    "#     # Split the data into separate JSON strings\n",
    "#     json_objects = raw_data.strip().split('\\n')\n",
    "\n",
    "#     # Parse the JSON objects\n",
    "#     parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "#     # Extract relevant fields\n",
    "#     extracted_data = []\n",
    "#     for item in parsed_data:\n",
    "#         response_body = item['response']['body']\n",
    "#         usage = response_body['usage']\n",
    "#         choice = response_body['choices'][0]\n",
    "        \n",
    "#         extracted_data.append({\n",
    "#             'batch_id': item['id'],\n",
    "#             'custom_id': item['custom_id'],\n",
    "#             'status_code': item['response']['status_code'],\n",
    "#             'request_id': item['response']['request_id'],\n",
    "#             'completion_id': response_body['id'],\n",
    "#             'model': response_body['model'],\n",
    "#             'created': response_body['created'],\n",
    "#             'assistant_message': choice['message']['content'],\n",
    "#             'finish_reason': choice['finish_reason'],\n",
    "#             'prompt_tokens': usage['prompt_tokens'],\n",
    "#             'completion_tokens': usage['completion_tokens'],\n",
    "#             'total_tokens': usage['total_tokens'],\n",
    "#             'system_fingerprint': response_body['system_fingerprint']\n",
    "#         })\n",
    "\n",
    "#     # Convert to DataFrame\n",
    "#     df = pd.DataFrame(extracted_data)\n",
    "\n",
    "#     df[['pid', 'domain', 'reap_id', 'dimension']] = df['custom_id'].str.split('-', expand=True)\n",
    "#     df['reap_id'] = df['reap_id'].astype(int)\n",
    "#     df['code'] = df['assistant_message'].str.extract(r'Code\\[(\\d)\\]')\n",
    "#     # merge reaps\n",
    "#     df = df.merge(df_reaps_merge, left_on='reap_id', right_on='reap_id', how='left')\n",
    "#     # merge issues\n",
    "#     df = df.merge(df_issues_merge, left_on='issue_id', right_on='issue_id', how='left')\n",
    "#     # df['code'] = df['code'].astype(int)\n",
    "    \n",
    "#     return df\n",
    "    \n",
    "    \n",
    "\n",
    "# primals_dfs = []\n",
    "# for i, data in enumerate([primals_1, primals_2]):\n",
    "#     data = data.text\n",
    "#     df = convert_batch_output_to_pd(data)\n",
    "#     df['batch'] = i + 1\n",
    "#     primals_dfs.append(df)\n",
    "    \n",
    "# values_dfs = []\n",
    "# for i, data in enumerate([values_1, values_2, values_3]):\n",
    "#     data = data.text\n",
    "#     df = convert_batch_output_to_pd(data)\n",
    "#     df['batch'] = i + 1\n",
    "#     values_dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_uncertainty = \"\"\"\n",
    "<ignore>{salt}</ignore>\n",
    "\n",
    "You are an expert qualitative coder analyzing a persons description of an emotional issue.\n",
    "Your task is to assess how uncertain the person about what is happening in their issue, where uncertainty is an appraisal dimension. \n",
    "Uncertainty reflects how unclear, ambiguous, or tentative the person is in describing their emotions, events, or interpretations.\n",
    "\n",
    "Rate the level of uncertainty using the following scale:\n",
    "\t-\t5 (Very Certain): The person is clear, confident, and decisive in their description, with no apparent doubt or ambiguity.\n",
    "\t-\t4 (Mostly Certain): The description is mostly clear, with occasional minor hesitations or vagueness.\n",
    "\t-\t3 (Moderately Uncertain): The person expresses some ambiguity or doubt, with noticeable hedging or a lack of clarity in parts of the narrative.\n",
    "\t-\t2 (Highly Uncertain): The description contains frequent hesitations, contradictions, or significant vagueness, suggesting a high level of doubt or ambiguity.\n",
    "\t-\t1 (Extremely Uncertain): The person is very unclear, vague, or contradictory throughout their description, indicating extreme uncertainty.\n",
    "\n",
    "Very briefly (1-3 sentences) walk through your thought process about how uncertain the individual is regarding the emotional issue they're facing and\n",
    "then at the end provide a rating from 1 to 5 formatted as follows:\n",
    "\n",
    "- `Rating[5]` for very certain\n",
    "- `Rating[4]` for mostly certain\n",
    "- `Rating[3]` for moderately uncertain\n",
    "- `Rating[2]` for highly uncertain\n",
    "- `Rating[1]` for extremely uncertain\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "all_pids = df_reaps['participant_id'].unique()\n",
    "all_domains = [\"career\", \"relationship\"]\n",
    "with open(\"batch_uncertainty.jsonl\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    \n",
    "    for pid, domain in itertools.product(all_pids, all_domains):\n",
    "        \n",
    "        \n",
    "        # Generate a random salt\n",
    "        salt = os.urandom(8).hex()\n",
    "        \n",
    "        sys_prompt = prompt_uncertainty.format(salt=salt)\n",
    "        \n",
    "        # get messages for pid domain\n",
    "        msg_df = df_messages.loc[(df_messages['participant_id'] == pid) & (df_messages['domain'] == domain) & (df_messages['state'] == 'issue')]\n",
    "        # sort by id\n",
    "        msg_df = msg_df.sort_values('id')\n",
    "        \n",
    "        # turn into a list of messages\n",
    "        msgs = []\n",
    "        for _, msg in msg_df.iterrows():\n",
    "            if (msg[\"role\"] == \"assistant\") and (\"tell me about an issue in your life that\" in msg[\"content\"]):\n",
    "                continue\n",
    "            # if content is nan, skip\n",
    "            if pd.isna(msg[\"content\"]):\n",
    "                continue\n",
    "            msgs.append({\n",
    "                \"role\": msg[\"role\"],\n",
    "                \"content\": msg[\"content\"]\n",
    "            })\n",
    "        \n",
    "        sys_prompt_msgs = msgs + [{\"role\": \"system\", \"content\": sys_prompt}]\n",
    "        \n",
    "        data = {\n",
    "            \"custom_id\": f\"{pid}-{domain}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL,\n",
    "                \"messages\": sys_prompt_msgs,\n",
    "                \"temperature\": TEMP,\n",
    "                \"max_tokens\": 120,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "\n",
    "        # Write each request as one line of JSON\n",
    "        f_out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-FRKrs5yr3KTJ9KC2c1dp6P', bytes=2918471, created_at=1737422914, filename='batch_uncertainty.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Batch(id='batch_678ef845fbe48190941795610b5417a1', completion_window='24h', created_at=1737422918, endpoint='/v1/chat/completions', input_file_id='file-FRKrs5yr3KTJ9KC2c1dp6P', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1737509318, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Chunk 1 of batch processing - uncertainty 3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to read and split the JSONL file into chunks of 50k lines\n",
    "def read_and_split_jsonl(file_path, max_lines=50000):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Split the lines into chunks of max_lines\n",
    "    chunks = [lines[i:i + max_lines] for i in range(0, len(lines), max_lines)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Read and split the original file\n",
    "file_path = \"batch_uncertainty.jsonl\"\n",
    "chunks = read_and_split_jsonl(file_path)\n",
    "\n",
    "# Process each chunk with the original filename\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a temporary in-memory file-like object to upload\n",
    "    from io import BytesIO\n",
    "    \n",
    "    temp_file = BytesIO(\"\".join(chunk).encode(\"utf-8\"))\n",
    "    temp_file.name = file_path  # Keep the original filename\n",
    "\n",
    "    # Upload each chunk\n",
    "    batch_input_file = client.files.create(\n",
    "        file=temp_file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "\n",
    "    # Create a batch for each chunk\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Chunk {i + 1} of batch processing - uncertainty 3\"\n",
    "        }\n",
    "    )\n",
    "    print(batch_obj)\n",
    "\n",
    "    temp_file.close()  # Close the in-memory file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "uncertainty_1_file_id = \"file-JqheSw2CHKXhZvAgP9tnPT\"\n",
    "uncertainty_2_file_id = \"file-C82tTvU2jp616U3YGptkUC\"\n",
    "uncertainty_3_file_id = \"file-DzbxdrvPWDPFEucEgpvmC3\"\n",
    "\n",
    "uncertainty_1_content = client.files.content(uncertainty_1_file_id)\n",
    "uncertainty_2_content = client.files.content(uncertainty_2_file_id)\n",
    "uncertainty_3_content = client.files.content(uncertainty_3_file_id)\n",
    "\n",
    "\n",
    "uncertainty_1_text = uncertainty_1_content.text\n",
    "uncertainty_2_text = uncertainty_2_content.text\n",
    "uncertainty_3_text = uncertainty_3_content.text\n",
    "\n",
    "uncertainty_1 = [json.loads(obj) for obj in uncertainty_1_text.strip().split('\\n')]\n",
    "uncertainty_2 = [json.loads(obj) for obj in uncertainty_2_text.strip().split('\\n')]\n",
    "uncertainty_3 = [json.loads(obj) for obj in uncertainty_3_text.strip().split('\\n')]\n",
    "\n",
    "# uncertainty_combined = uncertainty_1 + uncertainty_2 + uncertainty_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uncertainty_list = []\n",
    "for obj in uncertainty_1:\n",
    "    new_obj = {\n",
    "        \"pid\": obj[\"custom_id\"].split(\"-\")[0],\n",
    "        \"domain\": obj[\"custom_id\"].split(\"-\")[1],\n",
    "        \"assistant_message\": obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"],\n",
    "        \"batch\": 1\n",
    "    }\n",
    "    uncertainty_list.append(new_obj)\n",
    "for obj in uncertainty_2:\n",
    "    new_obj = {\n",
    "        \"pid\": obj[\"custom_id\"].split(\"-\")[0],\n",
    "        \"domain\": obj[\"custom_id\"].split(\"-\")[1],\n",
    "        \"assistant_message\": obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"],\n",
    "        \"batch\": 2\n",
    "    }\n",
    "    uncertainty_list.append(new_obj)\n",
    "for obj in uncertainty_3:\n",
    "    new_obj = {\n",
    "        \"pid\": obj[\"custom_id\"].split(\"-\")[0],\n",
    "        \"domain\": obj[\"custom_id\"].split(\"-\")[1],\n",
    "        \"assistant_message\": obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"],\n",
    "        \"batch\": 3\n",
    "    }\n",
    "    uncertainty_list.append(new_obj)\n",
    "\n",
    "uncertainty_df = pd.DataFrame(uncertainty_list)\n",
    "uncertainty_df['rating'] = uncertainty_df['assistant_message'].str.extract(r'Rating\\[(\\d)\\]')\n",
    "uncertainty_df['rating'] = uncertainty_df['rating'].str.extract(r'(\\d)')\n",
    "uncertainty_df['rating'] = uncertainty_df['rating'].astype(int)\n",
    "\n",
    "uncertainty_wide_df = uncertainty_df.pivot(index=[\"pid\", \"domain\"], columns=\"batch\", values=[\"assistant_message\", \"rating\"])\n",
    "\n",
    "# Flatten the multi-level columns for readability\n",
    "uncertainty_wide_df.columns = [f\"{col[0]}_{col[1]}\" for col in uncertainty_wide_df.columns]\n",
    "\n",
    "# Reset index for better usability\n",
    "uncertainty_wide_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# print(uncertainty_wide_df.rating.value_counts())\n",
    "# print(uncertainty_df['rating'].value_counts())\n",
    "\n",
    "uncertainty_wide_df.to_csv(\"uncertainty_coding_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>summary</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test-20250107_163900</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-07 16:38:56.104675</td>\n",
       "      <td>2025-01-07 16:38:56.104690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>test-20250107_163900</td>\n",
       "      <td>relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-07 16:38:56.104675</td>\n",
       "      <td>2025-01-07 16:38:56.104690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>test-20250107_163715</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-07 16:42:10.269918</td>\n",
       "      <td>2025-01-07 16:42:10.269968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>test-20250107_163715</td>\n",
       "      <td>relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-07 16:42:10.269918</td>\n",
       "      <td>2025-01-07 16:42:10.269968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>test-20250107_165457</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-07 16:54:54.111640</td>\n",
       "      <td>2025-01-07 16:54:54.111652</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>707</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>career</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>You are experiencing a significant drop in inc...</td>\n",
       "      <td>2025-01-08 20:20:17.544185</td>\n",
       "      <td>2025-01-08 20:37:20.284298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>705</td>\n",
       "      <td>66639f08a4e81235c3d7a659</td>\n",
       "      <td>career</td>\n",
       "      <td>67.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>You are facing challenges with maintaining wor...</td>\n",
       "      <td>2025-01-08 20:07:58.468453</td>\n",
       "      <td>2025-01-08 20:37:53.105463</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>710</td>\n",
       "      <td>65e1204f1bee2811d7894471-2</td>\n",
       "      <td>relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-08 20:39:11.679525</td>\n",
       "      <td>2025-01-08 20:39:11.679526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>65e1204f1bee2811d7894471-2</td>\n",
       "      <td>career</td>\n",
       "      <td>38.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-08 20:39:11.679514</td>\n",
       "      <td>2025-01-08 21:05:40.550235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>708</td>\n",
       "      <td>66da38dc1d5b9365584508ca</td>\n",
       "      <td>relationship</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You are experiencing problems with your attitu...</td>\n",
       "      <td>2025-01-08 20:20:17.544197</td>\n",
       "      <td>2025-01-08 20:43:05.765162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id              participant_id        domain   neg   pos  \\\n",
       "0      1        test-20250107_163900        career   NaN   NaN   \n",
       "1      2        test-20250107_163900  relationship   NaN   NaN   \n",
       "2      3        test-20250107_163715        career   NaN   NaN   \n",
       "3      4        test-20250107_163715  relationship   NaN   NaN   \n",
       "4      5        test-20250107_165457        career   NaN   NaN   \n",
       "..   ...                         ...           ...   ...   ...   \n",
       "705  707    66da38dc1d5b9365584508ca        career  60.0   4.0   \n",
       "706  705    66639f08a4e81235c3d7a659        career  67.0  30.0   \n",
       "707  710  65e1204f1bee2811d7894471-2  relationship   NaN   NaN   \n",
       "708  709  65e1204f1bee2811d7894471-2        career  38.0  50.0   \n",
       "709  708    66da38dc1d5b9365584508ca  relationship  67.0   1.0   \n",
       "\n",
       "                                               summary  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "705  You are experiencing a significant drop in inc...   \n",
       "706  You are facing challenges with maintaining wor...   \n",
       "707                                                NaN   \n",
       "708                                                NaN   \n",
       "709  You are experiencing problems with your attitu...   \n",
       "\n",
       "                     created_at                  updated_at  deleted_at  \n",
       "0    2025-01-07 16:38:56.104675  2025-01-07 16:38:56.104690         NaN  \n",
       "1    2025-01-07 16:38:56.104675  2025-01-07 16:38:56.104690         NaN  \n",
       "2    2025-01-07 16:42:10.269918  2025-01-07 16:42:10.269968         NaN  \n",
       "3    2025-01-07 16:42:10.269918  2025-01-07 16:42:10.269968         NaN  \n",
       "4    2025-01-07 16:54:54.111640  2025-01-07 16:54:54.111652         NaN  \n",
       "..                          ...                         ...         ...  \n",
       "705  2025-01-08 20:20:17.544185  2025-01-08 20:37:20.284298         NaN  \n",
       "706  2025-01-08 20:07:58.468453  2025-01-08 20:37:53.105463         NaN  \n",
       "707  2025-01-08 20:39:11.679525  2025-01-08 20:39:11.679526         NaN  \n",
       "708  2025-01-08 20:39:11.679514  2025-01-08 21:05:40.550235         NaN  \n",
       "709  2025-01-08 20:20:17.544197  2025-01-08 20:43:05.765162         NaN  \n",
       "\n",
       "[710 rows x 9 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
